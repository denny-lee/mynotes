mongo新增用户：
 db.createUser({user:"test",pwd:"test",roles:[{role:"readWrite",db:"liwtest"}]})
注意，这条指令指定了db的角色，但连接时只能用test这个db做auth.不然没权限

对应的项目里，credentail也必须是用test库，但morphia可以是其它的库

Group查询，可以使用AggregationPipeline.注意必须要有个ID
如果有日期，需要按不同精度来group的，可以先用Projection投射，来把日期处理成相应精度。再group

Datastore ds = dao.getDatastore();
        Query<Object> q = ds.getQueryFactory().createQuery(ds);
        BasicDBObject fmt = new BasicDBObject();
        fmt.append("format", "%Y-%m-%d");
        fmt.append("date", "$createGmt");
        Projection func = expression("$dateToString", fmt);
        AggregationPipeline pipeline = ds.createAggregation(Teacher.class).project(projection("newDate", func))
                .group(
                        id(grouping("newDate")),
                        grouping("count", new Accumulator("$sum", 1)),
                        grouping("totalAge", sum("age"))
                )
                .sort(Sort.ascending("count"));
        Iterator<Group> it = pipeline.aggregate(Group.class);
        int i = 0;
        while (it.hasNext()) {
            Group g = it.next();
            System.out.println(g);
            i++;
        }
        System.out.println("document count: "+ i);
		




Mongo事务方案：

解决方案1：字段同步
这种解决方案的使用场景最简单，最常见：文档间有些字段需要保持“同步”。例如，你有一个用户名为“John”的用户文档，文档代表John发表过的评论。如果用户可以更换用户名，那么这个改变需要发送给所有文档，即使进程中有应用错误或数据库错误。
为了实现这一目标，一个简单的办法是在主文档（这个情况下主文档是用户文档）中使用一个新字段（如“syncing”）。给“syncing”设置一个日期时间戳，记录用户文档的更新。

然后应用会修改所有的评论文档。结束后，需要移除标识：

现在假设进程中出现了问题：有些评论使用的是旧用户名。不过这些地方仍然会保留标识，所以应用知道哪些进程需要重新进行。因此，你需要后台进程在指定的时间（如1小时）检查“syncing”文件是否有未完成的地方。索引应设为“sparse”，这样只有实际设置的文档需要被索引，索引量就会比较小。

因此，系统通常可以保持事情在短时间内同步，在系统故障的情况下，时间周期为一个小时。如果时间不重要，当探测到“syncing”标志时，应用可以轻易修复文档。


解决方案2：作业队列
以上原理良好工作的前提是应用不需要很多内容，只依赖于通用进程（如：复制一个值）。一些事务需要执行特定变化，这些变化稍后很难识别。例如，用户文档包括一个朋友列表：

现在A和B决定成为朋友：你需要把B添加到A的列表，也需要把A添加到B的列表。如果两者没有同时发生也没有关系（只要没有引发困扰）。针对这种情况和大多数事务问题的解决方案是使用作业队列，作业队列也存储在MongoDB。一个作业文档就像这样：

或者是原始线程可以插入作业转发改变，或者是“worker”线程可以捡起工作。worker使用findAndModify()获取最原始的未加工的工作，findAndModify()是完全原子性的。操作中findAndModify()将工作标注为将被处理，同时也会表明worker name、当前时间以便于追踪。{ state: 1, ts: 1 } 上的索引使这些调用很迅速。

之后worker以一种幂等的方式对双方用户文档进行修改，这些改变能应用很多次，并且有同样的效果——这很重要！为了这个目的，我们只需要使用一个$addToSet。一种更通用的替代方式是在查询端添加一个测试，检测修改是否执行了。

最后一步是删除作业或标注作业完成。再保留一段时间作业是一种安全的方式，唯一的缺点是随着时间的流逝，先前的索引会变得越来越大，尽管你可以在指定域{ undone: 1 } 上使用稀疏索引，并且根据实际情况修改查询。

如果进程在某一时刻故障了，作业仍然会在队列中，并标注为处理中。后台进程停止一段时间后会将作业标注为需要再次处理，然后作业会重新从头开始。



解决方案3：二阶段提交


解决方案4：Log Reconciliation
很多财务系统常用的解决方案是log reconciliation。这种解决方案将事务写作简单的日志，这避免了复杂性和潜在的故障。然后从上次良好状态以来所有的变化推测当前账户的状态。在极端情况下，你可以清空账户，然后通过实施从第一天以来所有的变化重建账户……这听起来很恐怖，但是可行。账户文件需要一个“缓存”来提高速度，还需要一个seqId，seqId计算如下：

执行事务时，一个典型的财务系统会给事务写一个条目，会给与事务有关的账户写一个“账户变化”条目。这个方法需要进一步的写保证，“作业队列”解决方案可以实现写保证，事务中所有的作业在所有账户更改写入前都会保持不变。不过有了MongoDB，我们可以写一个包括事务和账户更改的文档。这个文档应该嵌入tx集合



解决方案5：版本控制
有时变得很复杂，以至于不能再JSON中表示，这些变更可能涉及很多有着复杂关系的文件（如树结构）。如果仅是部分变化（如破坏树）将会很混乱，这种情况下我们需要隔离。获取隔离性的一种方式是插入有着高版本号的新文档，取代对现有文档的更新。可以通过同日志和解同样的技术很容易、很安全的获得新版本号。通常{ itemId: 1, version: 1}上有一个独特的索引。
嵌入文档的应用从子文档开始，到主文档结束（如根节点）。当获取数据时，应用检查主文档的版本号，忽略高于版本号高于此版本号的文档。未完成的事务可以保持原状，可以忽略，可以清楚。